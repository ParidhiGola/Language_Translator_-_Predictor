{"cells":[{"cell_type":"markdown","metadata":{"id":"JoJPolOgWGG4"},"source":["### Load tensorflow"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1646275643426,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"zlt_1eHPWGG6"},"outputs":[],"source":["import tensorflow as tf\n","tf.compat.v1.reset_default_graph()\n","tf.compat.v1.set_random_seed(42)\n","#tf.reset_default_graph()\n","#tf.set_random_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"VzxABbMJWGG-"},"source":["### Read the data\n","<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":383,"status":"ok","timestamp":1646275644168,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"ommjMLuF75Dk","outputId":"9323836d-7161-48ff-e668-a8da6f1dc56e"},"outputs":[{"output_type":"stream","name":"stdout","text":["hin-eng.zip  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1646275644169,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"1vDoJM0zWGG_","outputId":"19584cf3-8d2e-40f8-b3a3-17cf31b84386"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-03 02:47:23--  http://www.manythings.org/anki/hin-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3033::ac43:ba36, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 133034 (130K) [application/zip]\n","Saving to: ‘hin-eng.zip.1’\n","\n","hin-eng.zip.1       100%[===================>] 129.92K  --.-KB/s    in 0.09s   \n","\n","2022-03-03 02:47:23 (1.43 MB/s) - ‘hin-eng.zip.1’ saved [133034/133034]\n","\n"]}],"source":["#You can use wget to download the file directly\n","!wget http://www.manythings.org/anki/hin-eng.zip\n","#!wget http://www.manythings.org/anki/spa-eng.zip "]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":585,"status":"ok","timestamp":1646275644750,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"A8soXgFrWGHB"},"outputs":[],"source":["import zipfile\n","import io\n","\n","#Read the zip file\n","zf = zipfile.ZipFile('hin-eng.zip', 'r')\n","\n","#Extract data from zip file\n","data = ''\n","with zf.open('hin.txt') as readfile:\n","  for line in io.TextIOWrapper(readfile, 'utf-8'):\n","    data += line"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1646275644751,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"SQFmYMvhWGHE","outputId":"bddef7b5-8b4e-4feb-ba89-ef3c64ae6055"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' (France) Attribution: tatoeba.org #631038 (Shishir) & #6179121 (fastrizwaan)\\nJump.\\tकूदो.\\tCC-BY 2.0 '"]},"metadata":{},"execution_count":9}],"source":["data[400:500]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1646275644752,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"V8g0NsaWpuqa"},"outputs":[],"source":["data = data[0:3300000]"]},{"cell_type":"markdown","metadata":{"id":"lx5AWe-0WGHT"},"source":["\n","### Extract Source and Target Language pairs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1646275644752,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"mjma2IuuWGHU","outputId":"f708e670-5c14-4972-c104-fdf3e7826f2d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"What's this?\\tयह क्या है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #413821 (CK) & #443158 (minshirui)\",\n"," 'Are you sick?\\tक्या तुम बीमार हो?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #434252 (lukaszpp) & #518699 (minshirui)',\n"," 'Bring him in.\\tउसको अंदर ले आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #307895 (CK) & #475932 (minshirui)',\n"," 'Come with us.\\tहमारे साथ आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433696 (CK) & #485546 (minshirui)',\n"," 'Happy Easter!\\tएसटर मुबारक हो!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #66762 (papabear) & #3189572 (pranjal710)']"]},"metadata":{},"execution_count":11}],"source":["#Split by newline character\n","data =  data.split('\\n')\n","\n","#Show some Data\n","data[100:105]"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1646275644753,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"Af9jau2XWGHX","outputId":"b84963b5-48e3-44a3-e92b-ed017b4b3572"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2935"]},"metadata":{},"execution_count":12}],"source":["len(data)"]},{"cell_type":"markdown","metadata":{"id":"A4ow84XDWGHb"},"source":["### Separate Source and Target pairs"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1646275644753,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"GTzjK4G6WGHb"},"outputs":[],"source":["encoder_text = [] #Initialize Source language list\n","decoder_text = [] #Initialize Target language list\n","\n","#Iterate over data\n","for line in data:\n","    try:\n","        in_txt, out_txt,_ = line.split('\\t')\n","        encoder_text.append(in_txt)\n","        \n","        # Add tab '<start>' as 'start sequence in target\n","        # And '<end>' as End\n","        decoder_text.append('<start> ' + out_txt + ' <end>')\n","    except:\n","        pass #ignore data which goes into error        "]},{"cell_type":"markdown","metadata":{"id":"4T4HJ3A9WGHd"},"source":["### Separate Source and Target pairs.."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1646275644754,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"xyZqwGuvWGHe","outputId":"dc18f2b3-d4a2-4279-bcfb-398e71ebc5cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[\"What's this?\", 'Are you sick?', 'Bring him in.', 'Come with us.', 'Happy Easter!', 'Has Tom left?', 'I am at home.', \"I can't move.\", \"I don't know.\", \"I don't know.\", 'I have a car.', 'I have a dog.', 'I understand.', \"I'm a doctor.\", 'It is a book.', \"It's snowing.\", \"It's too big.\", 'Please leave.', 'Unbelievable!', 'We are happy.', 'What is this?', 'Are you tired?', 'Can you drive?', 'Do you get it?', \"Don't get fat.\", \"Don't give in.\", 'Drink it down.', 'Everyone dies.', 'Flowers bloom.', 'I am who I am.', 'I know things.', 'I like donuts.', \"I'll take him.\", \"I'm tired now.\", \"I'm very busy.\", 'Is that a cat?', \"It's for free.\", \"It's for free.\", 'Let me try it.', 'Let me try it.', 'Let me try it.', \"Let's do that.\", 'Make it quick.', 'May I come in?', 'Open the door.', 'Open the door.', 'Please get in.', 'Read it again.', 'Read it aloud.', 'She bent down.', 'Some fish fly.', 'This is a map.', 'Tom is my son.', \"We're in town.\", 'Were you shot?', 'What about us?', 'Can I help you?', 'Can I help you?', 'Clean the room.', \"Don't touch it.\"]"]}],"source":["print(encoder_text[100:160],end = \"\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1646275644754,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"v2CILOS3WGHg","outputId":"de196e14-dc85-4121-b291-78cb706413b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<start> यह क्या है? <end>',\n"," '<start> क्या तुम बीमार हो? <end>',\n"," '<start> उसको अंदर ले आओ। <end>',\n"," '<start> हमारे साथ आओ। <end>',\n"," '<start> एसटर मुबारक हो! <end>']"]},"metadata":{},"execution_count":15}],"source":["decoder_text[100:105]"]},{"cell_type":"markdown","metadata":{"id":"CnRP431qWGHj"},"source":["### Tokenize Source language sentences"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1646275644755,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"9ucqBYr4WGHk","outputId":"512fca93-cbb1-437d-83ce-6687b2337008"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[173, 15], [20, 4, 402], [403, 29, 9], [50, 37, 81], [153, 1311]]"]},"metadata":{},"execution_count":16}],"source":["#Tokenizer for source language\n","encoder_t = tf.keras.preprocessing.text.Tokenizer()\n","encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n","encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n","encoder_seq[100:105] #Display some converted sentences"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1646275644755,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"zZv-TPVOWGHn","outputId":"896117ae-cf58-46dc-d774-b72c0a50f4d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sentence length for Source language:  22\n","Source language vocablury size:  2412\n"]}],"source":["#Maximum length of sentence\n","max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n","print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n","\n","#Source language Vocablury\n","encoder_vocab_size = len(encoder_t.word_index)\n","print('Source language vocablury size: ', encoder_vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"BeASC50tWGHr"},"source":["### Tokenize Target language sentences"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1646275644756,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"Zcyow_keWGHr"},"outputs":[],"source":["#Tokenizer for target language, filters should not <start> and <end>\n","#remove < and > used in Target language sequences\n","decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n","decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n","decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1646275644756,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"phLrIK6WWGHt","outputId":"4c89e2d7-d6a7-4fb3-9e5b-8a6dff32b234"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sentence length for Target language:  27\n","Target language vocablury size:  3036\n"]}],"source":["#Maximum length of sentence\n","max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n","print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n","\n","#Target language Vocablury\n","decoder_vocab_size = len(decoder_t.word_index)\n","print('Target language vocablury size: ', decoder_vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"6fXf48uMWGH6"},"source":["### Compare different sentences length"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646275644756,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"w0aRkCfiWGH7","outputId":"f1403e7c-3c32-40a3-d725-47733dcc2b93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length for sentence number 100:  2\n","Length for sentence number 2000:  7\n"]}],"source":["#Source Language sentences\n","print('Length for sentence number 100: ', len(encoder_seq[100]))\n","print('Length for sentence number 2000: ', len(encoder_seq[2000]))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646275644756,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"W2qZN4BvWGH_","outputId":"35fc9ae5-3041-4ec4-a51a-2df8da8a7788"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length for sentence number 100:  5\n","Length for sentence number 2000:  10\n"]}],"source":["#Target Language sentences\n","print('Length for sentence number 100: ', len(decoder_seq[100]))\n","print('Length for sentence number 2000: ', len(decoder_seq[2000]))"]},{"cell_type":"markdown","metadata":{"id":"wmeSCSs6WGIC"},"source":["### How do we make it same?"]},{"cell_type":"markdown","metadata":{"id":"mqps8juMWGIE"},"source":["### Padding the sentences"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646275644757,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"8rnbyRs9WGIF"},"outputs":[],"source":["#Source sentences\n","encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n","                                                                   maxlen=max_encoder_seq_length, #22\n","                                                                   padding='pre')\n","\n","#Target Sentences\n","decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n","                                                                   maxlen=max_decoder_seq_length, #27\n","                                                                   padding='post')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646275644757,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"a61g_ADpWGIH","outputId":"303abfcc-52dd-408c-91ce-fc893d4363da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Source data shape:  (2934, 22)\n","Target data shape:  (2934, 27)\n"]}],"source":["print('Source data shape: ', encoder_input_data.shape)\n","print('Target data shape: ', decoder_input_data.shape)"]},{"cell_type":"markdown","metadata":{"id":"Nl4oxg8cWGIJ"},"source":["#### Integer to Word converter for Decoder data"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1646275644757,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"jhwnBD-0WGIK"},"outputs":[],"source":["int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1646275644757,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"q8TP07uxWGIP","outputId":"d7d8f85b-61ad-417d-bbff-a97700c2a39e"},"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'हैं।'"]},"metadata":{},"execution_count":25}],"source":["int_to_word_decoder[15]"]},{"cell_type":"markdown","metadata":{"id":"5g4Y4oRvWGIV"},"source":["### Building Decoder Output"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1646275645060,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"},"user_tz":480},"id":"YuoPA9aWWGIV"},"outputs":[],"source":["import numpy as np\n","\n","#Initialize array\n","decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n","\n","#Shift Target output by one word\n","for i in range(decoder_input_data.shape[0]):\n","    for j in range(1,decoder_input_data.shape[1]):\n","        decoder_target_data[i][j-1] = decoder_input_data[i][j]"]},{"cell_type":"markdown","metadata":{"id":"haordQCuWGIX"},"source":["#### Convert target data in one hot vector"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Vs2SKKI5WGIY","executionInfo":{"status":"ok","timestamp":1646275645987,"user_tz":480,"elapsed":930,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Initialize one hot encoding array\n","decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n","                                   decoder_input_data.shape[1], #Number of words in each sentence\n","                                   len(decoder_t.word_index)+1)) #Vocab size + 1"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"xoX_6OP4WGIm","executionInfo":{"status":"ok","timestamp":1646275647193,"user_tz":480,"elapsed":1207,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Build one hot encoded array\n","for i in range(decoder_target_data.shape[0]):\n","    for j in range(decoder_target_data.shape[1]):\n","        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n","                                                                     num_classes=len(decoder_t.word_index)+1)    "]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Y5fO1TTWWGIo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646275647194,"user_tz":480,"elapsed":12,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"44ae6d94-f066-4414-aeb8-45be236c0145"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2934, 27, 3037)"]},"metadata":{},"execution_count":29}],"source":["decoder_target_one_hot.shape"]},{"cell_type":"markdown","metadata":{"id":"fQYFym0AWGIq"},"source":["### Building the Training Model"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"fRfYeB2AWGIr","executionInfo":{"status":"ok","timestamp":1646275647195,"user_tz":480,"elapsed":9,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Define config parameters\n","encoder_embedding_size = 50\n","decoder_embedding_size = 50\n","rnn_units = 256"]},{"cell_type":"markdown","metadata":{"id":"71ukvjyeWGIt"},"source":["#### Build Encoder"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"2SHW_YvkWGIw","executionInfo":{"status":"ok","timestamp":1646275647195,"user_tz":480,"elapsed":8,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Input Layer\n","encoder_inputs = tf.keras.layers.Input(shape=(None,))\n","\n","#Embedding layer\n","encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n","\n","#Get embedding layer output by feeding inputs\n","encoder_embedding_output = encoder_embedding(encoder_inputs)\n","\n","#---Following code has been commented out for Attention-------\n","#LSTM Layer and its output\n","#x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n","\n","#Build a list to feed Decoder\n","#encoder_states = [state_h, state_c]"]},{"cell_type":"markdown","metadata":{"id":"YbfLAFglWGIx"},"source":["#### Build Encoder - Get all hidden states"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"EnZJnNSbWGIz","executionInfo":{"status":"ok","timestamp":1646275647641,"user_tz":480,"elapsed":453,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Create LSTM Layer and get All hidden states, last hidden and cell state\n","encoder_lstm = tf.keras.layers.LSTM(rnn_units,return_state=True, return_sequences=True)\n","\n","#Get 3 outputs of LSTM Layer\n","encoder_all_h_states, state_h, state_c = encoder_lstm(encoder_embedding_output)\n","\n","#Build a list to feed Decoder\n","encoder_states = [state_h, state_c]"]},{"cell_type":"markdown","metadata":{"id":"RAIuXWK5WGI1"},"source":["#### Build Decoder"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"uYY-zwUSWGI2","executionInfo":{"status":"ok","timestamp":1646275648172,"user_tz":480,"elapsed":534,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Decode input - padded Target sentences\n","decoder_inputs = tf.keras.layers.Input(shape=(None,))\n","\n","#Decoder Embedding layer\n","decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n","\n","#Embedding layer output\n","decoder_embedding_output = decoder_embedding(decoder_inputs)\n","\n","#Decoder RNN\n","decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n","\n","#Decoder RNN Output, State initialization from Encoder states\n","#Output will be all hidden sequences, last 'h' state and last 'c' state\n","decoder_all_h_states,_,_ = decoder_rnn(decoder_embedding_output, \n","                                       initial_state=encoder_states)\n","\n","#---Following code has been commented out for Attention-------\n","#Output Layer\n","#decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n","\n","#Output of Dense layer\n","#decoder_outputs = decoder_dense(x)"]},{"cell_type":"markdown","metadata":{"id":"QwtwXesXWGI4"},"source":["#### Build Decoder...Alignment Matrix"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"mOJtf8kMWGI5","executionInfo":{"status":"ok","timestamp":1646275648172,"user_tz":480,"elapsed":14,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#1. Dot Product between Decoder_all_h_states and encoder_all_h_states\n","#2. Apply softmax to get Alignment matrix\n","\n","#Dimensions details\n","#decoder_all_states = batch_size x max_decoder_length x rnn_units\n","#encoder_all_states = batch_size x max_encoder_length x rnn_units\n","#score = batch_size x max_decoder_length x max_encoder_length\n","#alignment matrix = batch_size x max_decoder_length x max_encoder_length\n","\n","score = tf.keras.layers.dot([decoder_all_h_states, encoder_all_h_states], axes=2)\n","alignment_matrix = tf.keras.layers.Activation('softmax')(score)\n","\n","#Try general and concat approaches to alignment matrix"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"SNzzFkm4W0N8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646275648173,"user_tz":480,"elapsed":14,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"55887c1c-64e1-446f-9c86-2f281ce448af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, None, None) dtype=float32 (created by layer 'activation')>"]},"metadata":{},"execution_count":35}],"source":["alignment_matrix"]},{"cell_type":"markdown","metadata":{"id":"cYFfIGyvWGI6"},"source":["#### Build Decoder...Context Vector"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"h4ICneq6WGI6","executionInfo":{"status":"ok","timestamp":1646275648173,"user_tz":480,"elapsed":12,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Weighted sum of multiplication of Alignment matrix and encoder states\n","#Dimension of context_vector =  batch_size x max_decoder_length x rnn_units\n","\n","context_vector = tf.keras.layers.dot([alignment_matrix, encoder_all_h_states], axes=[2,1])"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"S3EtN7Ho9fHy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646275648173,"user_tz":480,"elapsed":11,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"50ed70f0-81cf-464a-9c22-47a10e915b94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, None, 256) dtype=float32 (created by layer 'dot_1')>"]},"metadata":{},"execution_count":37}],"source":["context_vector"]},{"cell_type":"markdown","metadata":{"id":"4GOKQuJiWGI8"},"source":["#### Build Decoder...Attention Vector"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"L9aJaK5LWGI8","executionInfo":{"status":"ok","timestamp":1646275648174,"user_tz":480,"elapsed":10,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Concatenate context vector and decoder_all_h_states\n","#context_decoder_hidden = batch_size x max_decoder_length x rnn_units\n","#attention_vector = batch_size x max_decoder_length x 128\n","\n","context_decoder_hidden = tf.keras.layers.concatenate([context_vector, \n","                                                      decoder_all_h_states])\n","\n","attention_dense_layer = tf.keras.layers.Dense(128, use_bias=False, \n","                                              activation='tanh')\n","\n","attention_vector = attention_dense_layer(context_decoder_hidden)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"v1nE-nHNfqix","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646275648174,"user_tz":480,"elapsed":10,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"c3c2a206-d980-40cd-fb36-1c90979a5a6e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, None, 128) dtype=float32 (created by layer 'dense')>"]},"metadata":{},"execution_count":39}],"source":["attention_vector"]},{"cell_type":"markdown","metadata":{"id":"yvcsEikBWGI-"},"source":["#### Build Decoder...Output layer"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"GinU4PH5WGI_","executionInfo":{"status":"ok","timestamp":1646275648175,"user_tz":480,"elapsed":10,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Output layer\n","decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n","\n","#With attention input will be attention_vector and not decoder_all_h_states\n","decoder_outputs = decoder_dense(attention_vector)"]},{"cell_type":"markdown","metadata":{"id":"__FmqX3qWGJL"},"source":["### Build Model using both Encoder and Decoder"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"IbtWE0_JWGJL","executionInfo":{"status":"ok","timestamp":1646275648175,"user_tz":480,"elapsed":9,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n","                              decoder_outputs) #Output of the model"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"WG4pyK_jWGJO","executionInfo":{"status":"ok","timestamp":1646275648175,"user_tz":480,"elapsed":8,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["model.compile(optimizer='adam', \n","              loss='categorical_crossentropy', \n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"uHhrDTBZWGJQ"},"source":["### Train the model"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"81ciKSvCWGJQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646276094578,"user_tz":480,"elapsed":446411,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"984099d1-bcb6-4003-b235-37d743cc0323"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","37/37 [==============================] - 22s 476ms/step - loss: 4.1327 - accuracy: 0.7180 - val_loss: 3.2997 - val_accuracy: 0.5917\n","Epoch 2/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.9719 - accuracy: 0.7381 - val_loss: 3.0143 - val_accuracy: 0.5917\n","Epoch 3/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.7480 - accuracy: 0.7381 - val_loss: 2.9737 - val_accuracy: 0.5917\n","Epoch 4/25\n","37/37 [==============================] - 19s 507ms/step - loss: 1.6582 - accuracy: 0.7396 - val_loss: 2.8875 - val_accuracy: 0.5949\n","Epoch 5/25\n","37/37 [==============================] - 16s 443ms/step - loss: 1.5576 - accuracy: 0.7522 - val_loss: 2.6397 - val_accuracy: 0.6108\n","Epoch 6/25\n","37/37 [==============================] - 16s 445ms/step - loss: 1.4596 - accuracy: 0.7754 - val_loss: 2.5831 - val_accuracy: 0.6299\n","Epoch 7/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.4031 - accuracy: 0.7816 - val_loss: 2.5358 - val_accuracy: 0.6347\n","Epoch 8/25\n","37/37 [==============================] - 16s 442ms/step - loss: 1.3667 - accuracy: 0.7857 - val_loss: 2.5157 - val_accuracy: 0.6364\n","Epoch 9/25\n","37/37 [==============================] - 17s 449ms/step - loss: 1.3393 - accuracy: 0.7887 - val_loss: 2.5264 - val_accuracy: 0.6368\n","Epoch 10/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.3182 - accuracy: 0.7901 - val_loss: 2.4941 - val_accuracy: 0.6406\n","Epoch 11/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.3004 - accuracy: 0.7919 - val_loss: 2.5328 - val_accuracy: 0.6387\n","Epoch 12/25\n","37/37 [==============================] - 16s 442ms/step - loss: 1.2844 - accuracy: 0.7925 - val_loss: 2.4950 - val_accuracy: 0.6412\n","Epoch 13/25\n","37/37 [==============================] - 16s 445ms/step - loss: 1.2689 - accuracy: 0.7933 - val_loss: 2.5069 - val_accuracy: 0.6416\n","Epoch 14/25\n","37/37 [==============================] - 16s 443ms/step - loss: 1.2578 - accuracy: 0.7934 - val_loss: 2.5076 - val_accuracy: 0.6426\n","Epoch 15/25\n","37/37 [==============================] - 16s 445ms/step - loss: 1.2441 - accuracy: 0.7946 - val_loss: 2.4850 - val_accuracy: 0.6432\n","Epoch 16/25\n","37/37 [==============================] - 16s 442ms/step - loss: 1.2317 - accuracy: 0.7952 - val_loss: 2.5010 - val_accuracy: 0.6428\n","Epoch 17/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.2196 - accuracy: 0.7958 - val_loss: 2.4930 - val_accuracy: 0.6438\n","Epoch 18/25\n","37/37 [==============================] - 17s 449ms/step - loss: 1.2069 - accuracy: 0.7965 - val_loss: 2.4998 - val_accuracy: 0.6450\n","Epoch 19/25\n","37/37 [==============================] - 16s 446ms/step - loss: 1.1940 - accuracy: 0.7971 - val_loss: 2.5548 - val_accuracy: 0.6436\n","Epoch 20/25\n","37/37 [==============================] - 16s 446ms/step - loss: 1.1805 - accuracy: 0.7982 - val_loss: 2.5072 - val_accuracy: 0.6457\n","Epoch 21/25\n","37/37 [==============================] - 17s 447ms/step - loss: 1.1650 - accuracy: 0.7996 - val_loss: 2.5013 - val_accuracy: 0.6465\n","Epoch 22/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.1489 - accuracy: 0.8011 - val_loss: 2.5026 - val_accuracy: 0.6462\n","Epoch 23/25\n","37/37 [==============================] - 16s 443ms/step - loss: 1.1318 - accuracy: 0.8029 - val_loss: 2.5268 - val_accuracy: 0.6469\n","Epoch 24/25\n","37/37 [==============================] - 16s 444ms/step - loss: 1.1139 - accuracy: 0.8041 - val_loss: 2.5139 - val_accuracy: 0.6472\n","Epoch 25/25\n","37/37 [==============================] - 16s 443ms/step - loss: 1.0947 - accuracy: 0.8062 - val_loss: 2.5242 - val_accuracy: 0.6474\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f00e018e3d0>"]},"metadata":{},"execution_count":43}],"source":["model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n","          batch_size=64,\n","          epochs=25,\n","          validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"0gO-p-OaWGJT"},"source":["### Save the model for later reuse"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"GUJcwtNyWGJU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646276103197,"user_tz":480,"elapsed":8629,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"e7162f91-76b1-46f1-c1ef-04c2d6f7b51d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: models/seq2seq_training_translation_attention.hd5/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: models/seq2seq_training_translation_attention.hd5/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f00e04390d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f00e02ace50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}],"source":["model.save('models/seq2seq_training_translation_attention.hd5')"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"PjuM6UkoWGJW","executionInfo":{"status":"ok","timestamp":1646276108579,"user_tz":480,"elapsed":5403,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["model = tf.keras.models.load_model('models/seq2seq_training_translation_attention.hd5')"]},{"cell_type":"markdown","metadata":{"id":"z8k64d1HWGJY"},"source":["# Building Model for Prediction"]},{"cell_type":"markdown","metadata":{"id":"_w__FLXCWGJZ"},"source":["### Build the Encoder Model to predict Encoder States"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"x9sSoCtMWGJZ","executionInfo":{"status":"ok","timestamp":1646276108580,"user_tz":480,"elapsed":25,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["encoder_model = tf.keras.models.Model(inputs=encoder_inputs, #Padded input sequences\n","                                      outputs=[encoder_all_h_states] + #Hidden states at all time steps\n","                                      encoder_states) #Hidden state and Cell state at last time step"]},{"cell_type":"markdown","metadata":{"id":"RScHHgr5WGJb"},"source":["### Build the Decoder Model \n","<p/>\n","\n","<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n","    <li><font color=\"blue\">Define Input for all encoder states - Attention Layer </font></li>\n","<li>Get Decoder RNN outputs along with h and c state</li>\n","<li><font color=\"blue\">Build Attention Layer</font></li>\n","<li><font color=\"blue\">Get Decoder Dense layer output using Attention vector</font></li>\n","    <li><font color=\"blue\">Build Model</font></li></ol>"]},{"cell_type":"markdown","metadata":{"id":"fZGRM_UQWGJc"},"source":["##### Step 1 - Define Input for both 'h' state and 'c' state initialization"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"Wq4XvgTAWGJc","executionInfo":{"status":"ok","timestamp":1646276108580,"user_tz":480,"elapsed":23,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Hidden state input\n","decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Cell state input\n","decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Putting it together\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"]},{"cell_type":"markdown","metadata":{"id":"U4rg9wJMWGJe"},"source":["##### Step 2 - Define Input encoder states - Attention Layer"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"SYozwBH2WGJe","executionInfo":{"status":"ok","timestamp":1646276108581,"user_tz":480,"elapsed":23,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["encoder_outputs = tf.keras.layers.Input(shape=(max_encoder_seq_length, rnn_units,))"]},{"cell_type":"markdown","metadata":{"id":"Cu7AJ7teWGJg"},"source":["##### Step 3 - Get Decoder RNN outputs along with h and c state"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"TPbxVkdoWGJh","executionInfo":{"status":"ok","timestamp":1646276108912,"user_tz":480,"elapsed":352,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Get Embedding layer output\n","x = decoder_embedding(decoder_inputs)\n","\n","#We will use the layer which we trained earlier\n","rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n","\n","#Why do we need this?\n","decoder_states = [state_h, state_c]"]},{"cell_type":"markdown","metadata":{"id":"YnDK-mtkWGJk"},"source":["##### Step 4 - Build Attention Layer"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"9RFkceyHWGJk","executionInfo":{"status":"ok","timestamp":1646276109304,"user_tz":480,"elapsed":395,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#Alignment score\n","p_score = tf.keras.layers.dot([rnn_outputs, encoder_outputs], axes=2)\n","\n","#Perform softmax to get Alignment matrix\n","p_alignment_matrix = tf.keras.layers.Activation('softmax')(p_score)\n","\n","#Context Vector\n","p_context_vector = tf.keras.layers.dot([p_alignment_matrix, encoder_outputs], axes=[2,1])\n","\n","#Build Attention Vector\n","# 1. Caoncatenate both context vector and decoder outputs\n","# 2. Feed it to the Dense layer \n","p_context_decoder_hidden = tf.keras.layers.concatenate([p_context_vector, rnn_outputs])\n","p_attention_vector = attention_dense_layer(p_context_decoder_hidden)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"CLw9G3KkWGJl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646276109304,"user_tz":480,"elapsed":8,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"86e792b4-ac44-4526-fbd4-234cafebaac5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<KerasTensor: shape=(None, None, 22) dtype=float32 (created by layer 'activation_1')>"]},"metadata":{},"execution_count":51}],"source":["p_alignment_matrix"]},{"cell_type":"markdown","metadata":{"id":"fUVTE025WGJn"},"source":["##### Step 5 - Get Decoder Dense layer output"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"o60fmWbJWGJo","executionInfo":{"status":"ok","timestamp":1646276109304,"user_tz":480,"elapsed":7,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["decoder_outputs = decoder_dense(p_attention_vector)"]},{"cell_type":"markdown","metadata":{"id":"oE7o-lOfWGJ3"},"source":["##### Step 6 - Build Decoder Model"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"545vI4cXWGJ4","executionInfo":{"status":"ok","timestamp":1646276109305,"user_tz":480,"elapsed":7,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["#3 Inputs - Word, h/c state and all hidden states from encoder\n","#3 Outputs - predicted word, h and c state values for next run and alignment matrix for visualization\n","\n","decoder_model = tf.keras.models.Model([decoder_inputs] +  #Start sequence and then word\n","                                      decoder_states_inputs + #h and c state value for initialization\n","                                      [encoder_outputs],  #Encoder all hidden states for Attention layer\n","                                      [decoder_outputs] + #Model word prediction\n","                                      decoder_states +   #h and c states for next run\n","                                      [p_alignment_matrix]) #for Alignment matrix"]},{"cell_type":"markdown","metadata":{"id":"G7VEzNGyWGJ5"},"source":["# Predicting output from Seq2Seq model"]},{"cell_type":"markdown","metadata":{"id":"mcg5mBcYWGJ6"},"source":["##### Build a prediction function"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"J1VoPsIkWGJ6","executionInfo":{"status":"ok","timestamp":1646276109305,"user_tz":480,"elapsed":7,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["def decode_sentence(input_sequence):\n","    \n","    #Get the encoder state values\n","    encoder_output =  encoder_model.predict(input_sequence)\n","    decoder_initial_states_value = encoder_output[1:]    \n","    encoded_seqs = encoder_output[0]\n","    \n","    #Build a sequence with '<start>' - starting sequence for Decoder\n","    target_seq = np.zeros((1,1))    \n","    target_seq[0][0] = decoder_t.word_index['<start>']\n","    \n","    #flag to check if prediction should be stopped\n","    stop_loop = False\n","    \n","    #Initialize predicted sentence\n","    predicted_sentence = ''\n","    \n","    #start the loop\n","    while not stop_loop:\n","        \n","        #Decoder model with 3 inputs\n","        predicted_outputs, h, c, a_matrix = decoder_model.predict([target_seq] + \n","                                                                  decoder_initial_states_value +\n","                                                                  [encoded_seqs])\n","        \n","        #Get the predicted word index with highest probability\n","        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n","        \n","        #Get the predicted word from predicter index\n","        if (predicted_output == 0):\n","            predicted_word = ' '\n","        else:\n","            predicted_word = int_to_word_decoder[predicted_output]\n","        \n","        #Check if prediction should stop\n","        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n","            \n","            stop_loop = True\n","            continue\n","                    \n","        #Updated predicted sentence\n","        if (len(predicted_sentence) == 0):\n","            predicted_sentence = predicted_word\n","        else:\n","            predicted_sentence = predicted_sentence + ' ' + predicted_word\n","            \n","        #Update target_seq to be the predicted word index\n","        target_seq[0][0] = predicted_output\n","        \n","        #Update initial states value for decoder\n","        decoder_initial_states_value = [h,c]\n","        \n","        #print(a_matrix)\n","    \n","    return predicted_sentence"]},{"cell_type":"markdown","metadata":{"id":"CuQcVTVZWGJ8"},"source":["##### Call Prediction function on a random sentence"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"jkJznTF8WGJ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646276110737,"user_tz":480,"elapsed":1437,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"d044bb8f-5224-49ac-f98c-a4726cfcb5a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------\n","Input sentence:  I want you to keep your promise.\n","Predicted sentence:  मैं मुझे एक एक बहुत नहीं नहीं\n"]}],"source":["#Generate a random number\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","\n","#Predict model output for 5 sentences\n","for i in range(start_num, start_num + 1):\n","    input_seq = encoder_input_data[i : i+1]\n","    #print(input_seq)\n","    predicted_sentence = decode_sentence(input_seq)\n","    print('--------')\n","    print ('Input sentence: ', encoder_text[i])\n","    print ('Predicted sentence: ', predicted_sentence )"]},{"cell_type":"markdown","metadata":{"id":"YS-RjZPlWGJ-"},"source":["##### Save encoder and decoder model"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"2l-qAT-bWGJ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646276119588,"user_tz":480,"elapsed":8855,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}},"outputId":"65d0d017-aa1d-4392-9c39-d90cf289104a"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: models/seq2seq_encoder_eng_hin.hd5/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: models/seq2seq_encoder_eng_hin.hd5/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f00e04390d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: models/seq2seq_decoder_eng_hin.hd5/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: models/seq2seq_decoder_eng_hin.hd5/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f00e02ace50> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}],"source":["#Compile models to avoid error\n","encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","\n","#Save the models\n","encoder_model.save('models/seq2seq_encoder_eng_hin.hd5')  #Encoder model\n","decoder_model.save('models/seq2seq_decoder_eng_hin.hd5')  #Decoder model"]},{"cell_type":"markdown","metadata":{"id":"Oh0okCv0WGKA"},"source":["##### Save encoder and decoder tokenizers"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"Qwfb-v7OWGKB","executionInfo":{"status":"ok","timestamp":1646276119589,"user_tz":480,"elapsed":21,"user":{"displayName":"Paridhi Bhargav","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17325204801395574142"}}},"outputs":[],"source":["import pickle\n","\n","pickle.dump(encoder_t,open('models/encoder_tokenizer_eng','wb'))\n","pickle.dump(decoder_t,open('models/decoder_tokenizer_hin','wb'))"]}],"metadata":{"colab":{"name":"2. Seq2Seq LSTM Model - Translation_with_prediction_Attention.ipynb","provenance":[],"collapsed_sections":["wmeSCSs6WGIC"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":0}